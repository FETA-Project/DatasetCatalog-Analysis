  acronym_info = "Short name of the dataset, which is used as the unique identifier. E.g., CESNET_TLS_Year22"
  acronym = "CESNET-QUIC22"
  acronym_aliases_info = "Additional alias for the Dataset Acronym (e.g. CESNET-TLS-Year22-XS). Used to filter the different subsection of the original dataset"
  acronym_aliases = ""
  title_info = "Full title of the dataset. E.g., CESNET-TLS-Year22"
  title = ""
  paper_title_info = "Full title of the original paper with the dataset"
  paper_title = ""
  authors = "Josef Koumar"
  description_info = "High-level description of the dataset. E.g., TLS capture from CESNET2 backbone network over one year (2022). The capture was done using high-speed monitoring probes at the perimeter of CESNET2 network. This dataset provides realistic characteristics of traffic originating from various web browsers, operating systems, mobile devices, desktop machines, and both HTTP/1.1 and HTTP/2 protocols."
  description = "CESNET-QUIC22 with nettisa features generate from PPI"
  format_info = "Dataset data format. E.g. json, csv, datazoo"
  format = "csv"
  doi_info = "DOI of this dataset"
  doi = ""
  origins_doi_info = "DOI of the original dataset"
  origins_doi = ""
  submitter = "Dominik <soukudom@cesnet.cz>"
  tags_info = "Use tags to categorize the dataset (comma separated)"
  tags = ""
  url = ""
  versions = "CESNET-QUIC22-XS-Nettisa"
  date_submitted = 2025-03-26T22:28:54.281872Z
  analysis_status = "Requested"
  files = []
  label_name = "APP"
  
  [collection_workflow]
   data_collection_tool = "script"
   data_collection_year = 2022
   feature_extraction_tool_info = "Tool that converts dataset to feature dataset. If any."
   feature_extraction_tool = "Nettisa script"
   feature_extraction_tool_description = "The script get-dataset.py loads the original dataset, process Per Packet Information (PPI) and calculate Nettisa feature vector"
   capture_config_parameters_info = "specific parameters that were used to capture dataset or feature dataset" 
   capture_config_parameters = " n/a "
   real_dataset_info = "Source of the dataset. E.g., real environment, testbed or generated."
   real_dataset = "yes"
   annotation_info = "Description of the dataset annotation. E.g., manual, automatic"
   annotation = "Automatic based on SNI field from TLS header in original dataset"
   [generic_info]
   capture_dates_info = "When was the dataset captured/generated"
   capture_dates = "31.10.2022 - 27.11.2022"
   classes = 101
   features = 80
   f1-score_info = "F1-score calculated based on NDVM tool [https://github.com/soukudom/NDVM]"
   f1-score = "0.998"
   performance_metric_info = "Perfomance metric defined by the author. Please define full specification e.g., F1-weighted"
   performance_metric_name = ""
   performance_metric_value = ""
   label_info = "Name of the field with label. In case this is unsupervised dataset, type None"
   label = "APP"
   known_issues_info = """Description of indentified issues in the dataset"""
   known_issues = """ n/a """
   key_observations_info = "List of known errors, drifts, limits, ... of the dataset"
   key_observations = """
   * Nettisa features are computed only from PPI information (limited to 30 packets)
   * Nettisa is usually more stable against datadrifts but has a lower classification performance
   """
   dataset_organization_info = "Structure of the dataset. E.g., per day, per capture, per device"
   dataset_organization = "per day"
   dataset_organization_description_info = "Description of the content of the organization. Is there any metadata?"
   dataset_organization_description = """Dataset is accessible via Datazoo framework which allows a convenient way to get data in python including various selection options. Iteration is possible per day as author claims. Nettisa script can be directly integrated to datazoo. The original dataset includes servicemap.csv to decode labels which can be applicable even to this dataset """
   dataset_documentation_info = "How to get started with the dataset. Ideally add example notebook."
   dataset_documentation = """
    Download the original CESNET-QUIC22 dataset and run get-dataset.py script. Labels are direcly encoded with numbers. They can be decoded by servicemap.csv metadata file.
   """
   used_dataset_info = "Script to get dataset for provided analysis"
   used_dataset = "get-dataset.py"
   dataset_application_info = "Where the dataset has been already applied."
   dataset_application = """
   * [1] 10.23919/CNSM62983.2024.10814630; MFWDD: Model-based Feature Weight Drift Detection Showcased on TLS and QUIC Traffic; [used; Validation of new method for drift detection]
   """
   per_class_data = """
  {"class A": 1, 
  "Class B": 265064, 
  Class C": 7755}
   """
   per_feature_data = """ 
  {"feature a": "feature a is ...",
   "feature b": "featre b is ..."}
  """
   [dataset_drift_analysis]
   description = """Drift analysis is used to see behavior of the dataset over time. In this section, you can see a comparison of two workflows: Dataset without retraining and dataset with retraining based on drift detection described in https://github.com/FETA-Project/MFWDD.
  This description contains summary results of drift counts and features and classes that caused the most drifts. In case you would like to see more detailed insights behind these summary numbers, please visit the included jupyter notebook, where you can even run your own queries."""
   drift_workflow = "Katoda-tls-ppi-drift-insights.ipynb"
  
  [dataset_drift_analysis.drifts_count]
  without_retraining = """
  {"Not Drifted": 31,
  "Drifted": 317}
  """
  
  retraining = """
  {"Not Drifted": 333,
  "Drifted": 13}
  """
  
  [dataset_drift_analysis.top_5]
  classes_without_retraining = """
  {"Firefox Accounts": 346,
  "Redmine (CESNET, MFF UK, KIV ZCU)": 344,
  "Alza WebAPI": 342,
  "Mozilla Telemetry": 340,
  "Xiaomi Account API": 339}
  """
  
  classes_retrainig = """
  {"Firefox Accounts": 244,
   "Apple Updates": 226,
   "Mozilla Telemetry": 222,
   "Aukro Backend": 216,
   "Redmine (CESNET, MFF UK, KIV ZCU)": 215}
  """
  features_without_retraining = """
  {"SIZE_4": 326,
  "DIR_2": 322,
  "PPI_LEN":315,
  "DIR_6": 310,
  "SIZE_10": 304}
  """
  
  features_retraining = """
   {"SIZE_1": 91,
   "DIR_30": 53,
   "DIR_29": 52,
   "DIR_28": 47,
   "DIR_27": 43}
  """
  
  [advanced_metrics]
  description = """
   
  Advanced metrics provides more detailed evalution of provided dataset to understand its content. List and meaning of advanced metrics is the following:
    
   * Permutation Slope: Shows linkage between data and labels. The higher metric the dataset and original labels have stronger relationship
   * P Value Status: Categorical metric to detect permutation p-value rules
   * Redundancy: Shows percentage of data samples that can we randomly deleted. The higher metric the more redundant samples
   * Similarity: Shows similarity of selected (main) class with the rest of classes. If the metric is above 1, they are different. If the metric is below 1, here is big similarity between classes.
  Calculation is done based on the following tool: https://github.com/soukudom/NDVM
  """
  perqoda_permutation_slope = "0.526" 
  p_value_status = "good"
  redundancy = "0.967"
  similarity = "4.093"
  advanced_metrics_workflow = "tbd"
  
  [dataset_comparison]
  description = "ML model comparison for this dataset"
  use_case = """ n/a """
  similar_dataset = """ n/a """
